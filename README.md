# Повторение результатов статьи 

Повторяем эксперимент из статьи

```
Bunel, R., Hausknecht, M., Devlin, J., Singh, R., & Kohli, P. (2018). 
Leveraging grammar and reinforcement learning for neural program synthesis. 
arXiv preprint arXiv:1805.04276.
```

В статье предлагается использовать обучение с подкреплением и отсев генерируемых вариантов программ путем из их исполнения и проверки синтаксиса.

Используется сгенерированный датасет [karel_dataset](https://msr-redmond.github.io/karel-dataset/).

Исходный код для начала эксперимента доступен на [Github](https://github.com/bunelr/GandRL_for_NPS).

## Как сдавать

 - [x] решить задания по задачам, ответы на вопросы привести в этом файле или добавить в нужном пункте ссылку на ответ
 - [x] оформить в виде git репозитория, в котором размещены все результаты
 - [x] прислать ссылку на репозиторий письмом

Для обучения моделей можно использовать Google Colab c GPU.

## Задача 1. Подготовка данных

### Задание 1. 

Получите karel_dataset, найдите в нем train.json и разберитесь в его структуре.

Вопросы
 - как правильно называется формат файла train.json?
 - > .ion [документация](https://amzn.github.io/ion-docs/)
 - как взять часть из файла train.json?
 - > cat train.json | head -n count
 - подготовьте файлы корректного формата размером 1%, 3%, 10% от оригинала train.json
 - > done
 
### Задание 2. 
 
Напишите код, который загружает данные из train.json
 
Вопросы
 - оцените объем необходимой RAM
 - > Немного, под одну запись. Загружаем построчно. Хватит 1GB
 - реализуйте загрузку в итератор словарей (паттерн итератор)
  
## Задача 2. Подготовка репозитория 

### Задание 1. 

Получите GandRL_for_NPS из github и смерджите его в этот репозиторий (см. [как это сделать](./FAQ.md#как-объединить-репозитории) в FAQ.md)

Вопросы
 - на каком языке реализован?
 - > python
 - что нужно сделать для установки эксперимента и зависимостей?
 - > Утсановить `cython`, запустить `setup.py`
 - где должны быть размещены данные?
 - > Где захотим, путь до них можно указать опцией. Но в примере предлагается папка `data/1m_6ex_karel/`
 - что нужно сделать для запуска эксперимента, как указать параметры и какие значения выбрать?
 - > запустить скрипт `train_cmd.py` с различными параметрами.
 - что нужно сделать для проверки обученной модели?
 - > запустить скрипт `eval_cmd.py` с сохраненными весами
 
### Задание 2. 
 
Загрузите 1% от train.json и остальные файлы из karel_dataset
 
Вопросы
 - зачем нужны файлы *.thdump в папке датасета?
 - что содержит new_vocab?
 - > словарь для разметки слов
 - где находится датасет для контроля и для теста?
 - > `val.json`, `test.json`
 - как устроен экземпляр данных для обучения?
 - > {"examples": [{"actions": programs, "example_index":, "inpgrid_json": {"blocked": , "cols": , "crashed":, "hero":, "markers":, "rows":}, "inpgrid_tensor":, "outgrid_json": {"blocked":, "cols":, "crashed":, "hero":, "markers":, "rows":}, "outgrid_tensor": }]

### Задание 3. 

Проведите эксперимент с 1% данных

Вопросы
 - как указать вид модели?
 - > Можно не указывать, а задат ьсвои параметры, но можно указать уже готовые веса `--init_weights`
 - какие ошибки возникли при запуске и как вы их устранили?
 - > Пришлось делать много cast_to_int, убрать ассерт, воспользоваться всеми подсказками зи FAQ
 - сколько эпох вы провели?
 - > 5
 - где сохранены результаты и логи эксперимента?
 - > `exps/supervised_use_grammar` - значение как в примере
 - какого качества получен результат?
 - > Loss : 1.11062 ValidationAccuracy : 0.000000.

 
### Задание 4. 
 
Сделайте свой клон репозитория с исправлениями, добавьте архивы подготовленных данных 1%, 3%, 10% на файлообменник с доступом по прямой ссылке
 
Вопросы
 - как получить данные по ссылке из командной строки?
 - > https://drive.google.com/file/d/14oXz87DMjqEWf4JmxG7fpU3q2ZbqT3rr/view?usp=sharing
 - где находится ваш репозиторий?
 - > Здесь [ссылка](https://github.com/MrBoogie27/automatic_programming_2)

### Задание 5*.

Подключите журналирование кривых обучения и промежуточных результатов в [TensorboardX](https://github.com/lanpa/tensorboardX). 
Для этого нужно использовать SummaryWriter для сохранения промежуточных значений функции потерь внутри цикла обучения. Например, после каждого минибатча или 100 миниматчей. 

Логи сохранять в подпапку ``runs`` папки эксперимента в ``./exps/*``

Для использования установить Tensorboard и указать данную папку в качестве исходной.
  
## Задача 3. Анализ и повторение результата

### Задание 1. 

Проведите эксперименты для 1%, 3%, 10% данных для MLE (supervised), RL_beam и обучаемой и предзаданной моделью синтаксиса

Вопросы
 - сколько времени заняло проведение эксперимента, какие ресурсы использовали?
 - > `google.colab`, `cuda`. 
 - какого качества удалось достичь?

| data  |  MLE (time) | MLE (accuracy) |
| ------------ | ------------ | ------------ |
| 1% (15 epoch)  |  1h 16min 5s  |  3.24 |
|  3% (10 epoch) |  1h 15min 1s  |  6.12  |
|  10% (5 epoch) |  42min 13s |  3.4 |
 - приведите 10 примеров синтеза программы для karel обученной моделью

Начните с MLE и используйте обученную таким образом модель для RL в качестве начального приближения.
См. подробнее в репозитории проекта.

### Задание 2. 

Подготовьте слайды по эксперименту: 
1. название статьи и постановка задачи (по статье, формулы) 
2. использованные данные (ссылка и как готовили)
3. постановка эксперимента (репо и команды запуска)
4. таблица с результатами (сводная)

Вопросы
 - сравните с результатами для Small dataset из статьи, удалось ли повторить их результаты?
 - как влияет выбор алгоритма контроля корректности программы на качество, в зависимости от размера?


